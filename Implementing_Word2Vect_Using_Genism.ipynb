{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6xM6oIiHOHs",
        "outputId": "b56e1f43-3f99-42ee-ff12-34a6dfaf43b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models.word2vec import LineSentence\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Preprocess the sentence\n",
        "sentence = \"The cat sat on the mat last night. Dog was barking. We love elephant\"\n",
        "# Tokenize the sentence into words\n",
        "tokens = word_tokenize(sentence.lower())  # Lowercasing for consistency\n",
        "print(\"Tokenized Sentence:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnKd7EkHHlPg",
        "outputId": "a587db3f-5544-4757-d7fb-c3e06e57a3c6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Sentence: ['the', 'cat', 'sat', 'on', 'the', 'mat', 'last', 'night', '.', 'dog', 'was', 'barking', '.', 'we', 'love', 'elephant']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Prepare data for Word2Vec\n",
        "# Word2Vec expects a list of tokenized sentences\n",
        "data = [tokens]  # Wrapping the tokenized sentence in a list to make it a list of sentences\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UxmH_qRHVtA",
        "outputId": "e7ac813e-881f-474f-b3ea-a0fd5812eade"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the',\n",
              "  'cat',\n",
              "  'sat',\n",
              "  'on',\n",
              "  'the',\n",
              "  'mat',\n",
              "  'last',\n",
              "  'night',\n",
              "  '.',\n",
              "  'dog',\n",
              "  'was',\n",
              "  'barking',\n",
              "  '.',\n",
              "  'we',\n",
              "  'love',\n",
              "  'elephant']]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(\n",
        "    sentences=data,\n",
        "    vector_size=100,  # Size of the word vectors\n",
        "    window=3,         # Context window size\n",
        "    min_count=1,      # Minimum frequency of words to be included\n",
        "    sg=0,             # Use Skip-gram model (1: Skip-gram; 0: CBOW)\n",
        "    workers=4,        # Number of threads for training\n",
        "    epochs=10         # Number of training epochs\n",
        ")"
      ],
      "metadata": {
        "id": "EcHkMbNIHZxg"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Analyze the trained Word2Vec model\n",
        "# Get the vector for a specific word\n",
        "word_vector = model.wv[\"cat\"]  # Get the vector representation for \"cat\"\n",
        "print(\"\\nVector for 'cat':\\n\", word_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_cnIBWOIUok",
        "outputId": "13d2cec7-375c-4859-bf20-6000e1d18533"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vector for 'cat':\n",
            " [-0.00950045  0.00956245 -0.0077711  -0.00264685 -0.00490687 -0.00496653\n",
            " -0.00802392 -0.00778332 -0.00455381 -0.00127546 -0.00510294  0.00614129\n",
            " -0.00951657 -0.00530794  0.00943732  0.0069913   0.00767612  0.0042349\n",
            "  0.00050782 -0.00598228  0.00601872  0.00263416  0.00770108  0.00639523\n",
            "  0.0079412   0.00865835 -0.00989559 -0.00675552  0.00133724  0.00644095\n",
            "  0.00737411  0.00551761  0.0076623  -0.00512609  0.006586   -0.00410858\n",
            " -0.00905581  0.00914177  0.0013301  -0.00275933 -0.00247751 -0.00422111\n",
            "  0.00481141  0.00440193 -0.00265271 -0.00734366 -0.00356605 -0.00033697\n",
            "  0.00609597 -0.00283844 -0.00012112  0.00088037 -0.00709547  0.00206405\n",
            " -0.0014327   0.00280145  0.00484033 -0.00135295 -0.00277946  0.00773816\n",
            "  0.005046    0.00671273  0.00451655  0.00866808  0.00747419 -0.00108195\n",
            "  0.00874769  0.00460273  0.00544039 -0.00138615 -0.0020413  -0.00442316\n",
            " -0.00851616  0.0030391   0.00888367  0.00892157 -0.00194196  0.00608665\n",
            "  0.00378018 -0.00429642  0.00204252 -0.00543816  0.00820977  0.00543369\n",
            "  0.00318285  0.00410201  0.00865828  0.00727358 -0.00083401 -0.00707351\n",
            "  0.00838135  0.00723331  0.00173075 -0.00134726 -0.00589027 -0.00453422\n",
            "  0.00864985 -0.00313532 -0.00633825  0.0098695 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find most similar words to a given word\n",
        "similar_words = model.wv.most_similar(\"cat\", topn=2)\n",
        "print(\"\\nMost similar words to 'cat':\", similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxHVqDPqIXjt",
        "outputId": "a6e6cd36-1b05-428b-c11b-dea60f4ea3bd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Most similar words to 'cat': [('we', 0.2529977262020111), ('the', 0.1370527595281601)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.doesnt_match([\"cat\", \"dog\", \"elephant\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pRgWwg9vKdB_",
        "outputId": "bc712fc7-8673-4280-c945-472aa6a9b402"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"word2vec_model.model\")\n",
        "\n",
        "# Load the model\n",
        "loaded_model = Word2Vec.load(\"word2vec_model.model\")\n",
        "print(\"\\nLoaded model similar words for 'cat':\", loaded_model.wv.most_similar(\"cat\", topn=5))\n"
      ],
      "metadata": {
        "id": "Oafo5HPmInyV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
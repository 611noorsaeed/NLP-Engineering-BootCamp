{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fea6b3a",
   "metadata": {},
   "source": [
    "# Basic\n",
    "\n",
    "Create a TextBlob         \n",
    "\n",
    "Part-of-speech Tagging\n",
    "\n",
    "Noun Phrase Extraction\n",
    "\n",
    "Sentiment Analysis\n",
    "\n",
    "Tokenization\n",
    "\n",
    "Words Inflection and Lemmatization\n",
    "\n",
    "WordNet Integration\n",
    "\n",
    "WordLists\n",
    "\n",
    "Spelling Correction\n",
    "\n",
    "Get Word and Noun Phrase Frequencies\n",
    "\n",
    "Parsing\n",
    "\n",
    "TextBlobs Are Like Python Strings!\n",
    "\n",
    "n-grams\n",
    "\n",
    "\n",
    "# End to End to Projects\n",
    "\n",
    "Sentiment Analysis on Customer Reviews\n",
    "\n",
    "Language Translation Tool\n",
    "\n",
    "Spell Checker for User Input\n",
    "\n",
    "Keyword Extraction from Text\n",
    "\n",
    "Text Summarization by Sentence Polarity\n",
    "\n",
    "Formality Checker for Text\n",
    "\n",
    "Subjectivity Analysis of Statements\n",
    "\n",
    "Sentence Tokenizer for Paragraphs\n",
    "\n",
    "Text Similarity Checker\n",
    "\n",
    "Text Complexity Scorer\n",
    "\n",
    "Parts of Speech (POS) Tagging\n",
    "\n",
    "Synonym Replacement Tool\n",
    "\n",
    "Custom Word Frequency Counter\n",
    "\n",
    "Named Entity Recognition (NER) using Custom Keywords\n",
    "\n",
    "Politeness Detector for Customer Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28f4b025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to C:\\Users\\Noor\n",
      "[nltk_data]     Saeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Noor\n",
      "[nltk_data]     Saeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Noor\n",
      "[nltk_data]     Saeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Noor Saeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package conll2000 to C:\\Users\\Noor\n",
      "[nltk_data]     Saeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to C:\\Users\\Noor\n",
      "[nltk_data]     Saeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb1e699",
   "metadata": {},
   "source": [
    "# Create a TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43317443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f4d1f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Python is a high-level, general-purpose programming language.\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = TextBlob(\"Python is a high-level, general-purpose programming language.\")\n",
    "wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d9b2d",
   "metadata": {},
   "source": [
    "# Parts of speech Taggings\n",
    "\n",
    "Each POS tag represents the grammatical role of the word in the sentence. Here’s the full form of each tag from your list:\n",
    "\n",
    "\n",
    "NNP: Proper Noun, Singular (e.g., \"Python\")\n",
    "\n",
    "VBZ: Verb, 3rd person singular present (e.g., \"is\")\n",
    "\n",
    "DT: Determiner (e.g., \"a\")\n",
    "\n",
    "JJ: Adjective (e.g., \"high-level\", \"general-purpose\")\n",
    "\n",
    "NN: Noun, Singular or Mass (e.g., \"programming,\" \"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46f83a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('high-level', 'JJ'),\n",
       " ('general-purpose', 'JJ'),\n",
       " ('programming', 'NN'),\n",
       " ('language', 'NN')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad657d",
   "metadata": {},
   "source": [
    "# Noun Phrase Extraction\n",
    "Similarly, noun phrases are accessed through the noun_phrases property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "304c5129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['python'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b29c3f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f06490e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "\n",
    "if testimonial.sentiment[0] >=0.1:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c48dc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "testimonial = TextBlob(\"I hate to start learning complex concepts first\")\n",
    "\n",
    "if testimonial.sentiment[0] >=0.1:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43af21",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "Word Base\n",
    "\n",
    "Sentence Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "503350cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Beautiful', 'is', 'better', 'than', 'ugly', 'Explicit', 'is', 'better', 'than', 'implicit', 'Simple', 'is', 'better', 'than', 'complex'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen = TextBlob(\n",
    "    \"Beautiful is better than ugly. \"\n",
    "    \"Explicit is better than implicit. \"\n",
    "    \"Simple is better than complex.\"\n",
    ")\n",
    "zen.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b78516d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Beautiful is better than ugly.\"),\n",
       " Sentence(\"Explicit is better than implicit.\"),\n",
       " Sentence(\"Simple is better than complex.\")]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd06a4f",
   "metadata": {},
   "source": [
    "# Words Inflection and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e093b23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Use', '4', 'spaces', 'per', 'indentation', 'level'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = TextBlob(\"Use 4 spaces per indentation level.\")\n",
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6002f7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'space'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[2].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6b323de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'levels'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[-1].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ed192ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'place'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "w = Word(\"places\")\n",
    "w.lemmatize('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8b0376e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word(\"went\")\n",
    "w.lemmatize(\"v\")  # Pass in WordNet part of speech (verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab74404b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word(\"loving\")\n",
    "w.lemmatize(\"v\")  # Pass in WordNet part of speech (verb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c195c6",
   "metadata": {},
   "source": [
    "# Wordnet integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31752768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('topographic_point.n.01'),\n",
       " Synset('place.n.02'),\n",
       " Synset('place.n.03'),\n",
       " Synset('place.n.04'),\n",
       " Synset('stead.n.01'),\n",
       " Synset('place.n.06'),\n",
       " Synset('home.n.01'),\n",
       " Synset('position.n.06'),\n",
       " Synset('position.n.01'),\n",
       " Synset('place.n.10'),\n",
       " Synset('seat.n.01'),\n",
       " Synset('place.n.12'),\n",
       " Synset('place.n.13'),\n",
       " Synset('plaza.n.01'),\n",
       " Synset('place.n.15'),\n",
       " Synset('space.n.07'),\n",
       " Synset('put.v.01'),\n",
       " Synset('place.v.02'),\n",
       " Synset('rate.v.01'),\n",
       " Synset('locate.v.03'),\n",
       " Synset('place.v.05'),\n",
       " Synset('place.v.06'),\n",
       " Synset('target.v.01'),\n",
       " Synset('identify.v.01'),\n",
       " Synset('place.v.09'),\n",
       " Synset('set.v.09'),\n",
       " Synset('place.v.11'),\n",
       " Synset('place.v.12'),\n",
       " Synset('invest.v.01'),\n",
       " Synset('station.v.01'),\n",
       " Synset('place.v.15'),\n",
       " Synset('place.v.16')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "from textblob.wordnet import VERB\n",
    "word = Word(\"places\")\n",
    "word.synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00db4d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chop.v.05'),\n",
       " Synset('hack.v.02'),\n",
       " Synset('hack.v.03'),\n",
       " Synset('hack.v.04'),\n",
       " Synset('hack.v.05'),\n",
       " Synset('hack.v.06'),\n",
       " Synset('hack.v.07'),\n",
       " Synset('hack.v.08')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"hack\").get_synsets(pos=VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e110daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a point located with respect to surface features of some region',\n",
       " 'any area set aside for a particular purpose',\n",
       " 'an abstract mental location',\n",
       " 'a general vicinity',\n",
       " 'the post or function properly or customarily occupied or served by another',\n",
       " 'a particular situation',\n",
       " 'where you live at a particular time',\n",
       " 'a job in an organization',\n",
       " 'the particular portion of space occupied by something',\n",
       " 'proper or designated social situation',\n",
       " 'a space reserved for sitting (as in a theater or on a train or airplane)',\n",
       " 'the passage that is being read',\n",
       " 'proper or appropriate position or location',\n",
       " 'a public square with room for pedestrians',\n",
       " 'an item on a list or in a sequence',\n",
       " 'a blank area',\n",
       " 'put into a certain place or abstract location',\n",
       " 'place somebody in a particular situation or location',\n",
       " 'assign a rank or rating to',\n",
       " 'assign a location to',\n",
       " 'to arrange for',\n",
       " 'take a place in a competition; often followed by an ordinal',\n",
       " 'intend (something) to move towards a certain goal',\n",
       " 'recognize as being; establish the identity of someone or something',\n",
       " 'assign to (a job or a home)',\n",
       " 'locate',\n",
       " 'estimate',\n",
       " 'identify the location or place of',\n",
       " 'make an investment',\n",
       " 'assign to a station',\n",
       " 'finish second or better in a horse or dog race',\n",
       " 'sing a note with the correct pitch']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"Place\").definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69099aa",
   "metadata": {},
   "source": [
    "# Spelling Correction & Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c388a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling!\n"
     ]
    }
   ],
   "source": [
    "b = TextBlob(\"I havv goood speling!\")\n",
    "print(b.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8284d94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lovely', 0.44776119402985076),\n",
       " ('lover', 0.3880597014925373),\n",
       " ('lovers', 0.13432835820895522),\n",
       " ('livery', 0.029850746268656716)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word(\"lovery\")\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee84a676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nice', 0.9636363636363636),\n",
       " ('nina', 0.01818181818181818),\n",
       " ('nick', 0.01818181818181818)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word(\"nica\")\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84a3f1b",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "\n",
    "Here's the breakdown of the tags in your example:\n",
    "\n",
    "Word: The actual word from the sentence.\n",
    "\n",
    "POS-tag: Part-of-speech tag, indicating the grammatical role of the word (e.g., \"CC\" for coordinating conjunction, \"RB\" for adverb, etc.).\n",
    "\n",
    "Chunk-tag: Indicates the beginning or continuation of a chunk (e.g., noun phrases, prepositional phrases). This uses B (beginning) and I (inside) tags to show chunk boundaries:\n",
    "\n",
    "B-NP: Beginning of a noun phrase\n",
    "\n",
    "I-NP: Inside a noun phrase\n",
    "\n",
    "B-PP: Beginning of a prepositional phrase\n",
    "\n",
    "B-ADVP: Beginning of an adverbial phrase\n",
    "\n",
    "O: Outside of any chunk\n",
    "\n",
    "Named-entity-tag: Marks named entities (e.g., organizations, locations) with specific tags. In your example, everything is tagged as O (Outside any named entity), meaning there are no named entities in this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a08ec4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And/CC/O/O now/RB/B-ADVP/O for/IN/B-PP/B-PNP something/NN/B-NP/I-PNP completely/RB/B-ADJP/O different/JJ/I-ADJP/O ././O/O\n"
     ]
    }
   ],
   "source": [
    "b = TextBlob(\"And now for something completely different.\")\n",
    "print(b.parse())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac508c",
   "metadata": {},
   "source": [
    "# n-gram (gram, bi-gram, tri-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09b9faba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now', 'is', 'better']),\n",
       " WordList(['is', 'better', 'than']),\n",
       " WordList(['better', 'than', 'never'])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"Now is better than never.\")\n",
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1c6fba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now']),\n",
       " WordList(['is']),\n",
       " WordList(['better']),\n",
       " WordList(['than']),\n",
       " WordList(['never'])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69195a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now', 'is']),\n",
       " WordList(['is', 'better']),\n",
       " WordList(['better', 'than']),\n",
       " WordList(['than', 'never'])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360f56a",
   "metadata": {},
   "source": [
    "# Project 1: Sentiment Analysis on Customer Reviews\n",
    "\n",
    "\n",
    "two possibilies\n",
    "\n",
    "Real Time Sentiment Detection\n",
    "\n",
    "Detection Sentiment from text (custom data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed799fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your text......or press exit to leave   I love to watch movies\n",
      "\n",
      "\n",
      "Positive\n",
      "Enter your text......or press exit to leave   we don't like this movies its so ugly\n",
      "\n",
      "\n",
      "negative\n",
      "Enter your text......or press exit to leave   i wanna go to USA\n",
      "\n",
      "\n",
      "Neutral\n",
      "Enter your text......or press exit to leave   we loves each other\n",
      "\n",
      "\n",
      "negative\n",
      "Enter your text......or press exit to leave   we love each other\n",
      "\n",
      "\n",
      "Positive\n",
      "Enter your text......or press exit to leave   exit\n",
      "\n",
      "\n",
      "Neutral\n",
      "Good Bye\n"
     ]
    }
   ],
   "source": [
    "# Real Time Detection\n",
    "from textblob import TextBlob\n",
    "while True:\n",
    "    input_text = input(\"Enter your text......or press exit to leave   \")\n",
    "    print(\"\\n\")\n",
    "    text = TextBlob(input_text)\n",
    "    sentiment = text.sentiment.polarity\n",
    "    if sentiment > 0:\n",
    "        print(\"Positive\")\n",
    "    elif sentiment==0:\n",
    "        print(\"Neutral\")\n",
    "    else:\n",
    "        print(\"negative\")\n",
    "    \n",
    "    if input_text == \"exit\":\n",
    "        print(\"Good Bye\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1ff5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on custom data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5995c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_detection(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = TextBlob(text)\n",
    "    \n",
    "    sentiment = text.sentiment.polarity\n",
    "    \n",
    "    if sentiment > 0:\n",
    "        return \"positive\"\n",
    "    elif sentiment < 0:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87651e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer name</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rishikumar Thakur</td>\n",
       "      <td>Another Midrange killer Smartphone by Xiaomi\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raza ji</td>\n",
       "      <td>All ok but vry small size mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vaibhav Patel</td>\n",
       "      <td>Quite good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Redmi has always have been the the king of bud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sudhakaran Wadakkancheri</td>\n",
       "      <td>worst product from MI. I am a hardcore fan of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Customer name                                           Comments\n",
       "0         Rishikumar Thakur  Another Midrange killer Smartphone by Xiaomi\\n...\n",
       "1                   Raza ji                   All ok but vry small size mobile\n",
       "2             Vaibhav Patel                                         Quite good\n",
       "3           Amazon Customer  Redmi has always have been the the king of bud...\n",
       "4  Sudhakaran Wadakkancheri  worst product from MI. I am a hardcore fan of ..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"redmi6.csv\", encoding='ISO-8859-1')\n",
    "df = df[['Customer name','Comments']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40f3f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['Comments'].apply(sentiment_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dacbb9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer name</th>\n",
       "      <th>Comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rishikumar Thakur</td>\n",
       "      <td>Another Midrange killer Smartphone by Xiaomi\\n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raza ji</td>\n",
       "      <td>All ok but vry small size mobile</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vaibhav Patel</td>\n",
       "      <td>Quite good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Redmi has always have been the the king of bud...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sudhakaran Wadakkancheri</td>\n",
       "      <td>worst product from MI. I am a hardcore fan of ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Rahul</td>\n",
       "      <td>I like This Phone, Awesome look and design.\\nI...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Sunil Soni</td>\n",
       "      <td>Product is avasome but invoice is note include...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>D.C.Padhi</td>\n",
       "      <td>Redmi Note4, Note5, now 6pro..It seems the old...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Mahesh</td>\n",
       "      <td>I love mi</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Vinod</td>\n",
       "      <td>Same old configurations with higher price.\\nNo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Customer name  \\\n",
       "0           Rishikumar Thakur   \n",
       "1                     Raza ji   \n",
       "2               Vaibhav Patel   \n",
       "3             Amazon Customer   \n",
       "4    Sudhakaran Wadakkancheri   \n",
       "..                        ...   \n",
       "275                     Rahul   \n",
       "276                Sunil Soni   \n",
       "277                 D.C.Padhi   \n",
       "278                    Mahesh   \n",
       "279                     Vinod   \n",
       "\n",
       "                                              Comments     label  \n",
       "0    Another Midrange killer Smartphone by Xiaomi\\n...  positive  \n",
       "1                     All ok but vry small size mobile  positive  \n",
       "2                                           Quite good  positive  \n",
       "3    Redmi has always have been the the king of bud...  positive  \n",
       "4    worst product from MI. I am a hardcore fan of ...  negative  \n",
       "..                                                 ...       ...  \n",
       "275  I like This Phone, Awesome look and design.\\nI...  positive  \n",
       "276  Product is avasome but invoice is note include...   neutral  \n",
       "277  Redmi Note4, Note5, now 6pro..It seems the old...  positive  \n",
       "278                                          I love mi  positive  \n",
       "279  Same old configurations with higher price.\\nNo...  positive  \n",
       "\n",
       "[280 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83e659f",
   "metadata": {},
   "source": [
    "# Project 2: Language Translation Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6219746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language translation is deprecated from textblob but we can use alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3a5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "\n",
    "# blob = TextBlob('TextBlob is a great tool for developers')\n",
    "# print(blob.translate(to='hi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1698ce",
   "metadata": {},
   "source": [
    "# Deep Translator (Google Translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21303cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je m'appelle noor saeed\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "text = \"my name is noor saeed\"\n",
    "print(GoogleTranslator(source='en', target='fr').translate(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "269d444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(text, target_lang):\n",
    "    trans_text = GoogleTranslator(target=target_lang).translate(text)\n",
    "    return trans_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e2dd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Language Translation tool...\n",
      "Enter your text....we appreciate each other\n",
      "To translate lang....ur\n",
      "Translation : ہم ایک دوسرے کی تعریف کرتے ہیں\n",
      "\n",
      " Language Translation tool...\n",
      "Enter your text....this is a cat\n",
      "To translate lang....hi\n",
      "Translation : यह एक बिल्ली है\n",
      "\n",
      " Language Translation tool...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print(\"\\n Language Translation tool...\")\n",
    "    input_text = input(\"Enter your text....\")\n",
    "    \n",
    "    if input_text == \"exit\":\n",
    "        break\n",
    "        \n",
    "    target_lang = input(\"To translate lang....\")\n",
    "    \n",
    "    trans_text = trans(input_text,target_lang)\n",
    "    print(\"Translation :\", trans_text)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b461f8",
   "metadata": {},
   "source": [
    "# Project 3: Spell Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81bcdb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "mytxt = \"i lov you\"\n",
    "text = TextBlob(mytxt)\n",
    "\n",
    "print(text.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f49f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries (Run this code in VS code or pycharm)\n",
    "import streamlit as st\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Streamlit app setup\n",
    "st.title(\"Real-Time Spell Checker\")\n",
    "st.write(\"Enter text with spelling errors below, and see the corrected version in real time.\")\n",
    "\n",
    "# Text input\n",
    "text = st.text_area(\"Type your text here:\", \"\")\n",
    "\n",
    "# Check if the input text is not empty\n",
    "if text:\n",
    "    # Use TextBlob for spell correction\n",
    "    blob = TextBlob(text)\n",
    "    corrected_text = blob.correct()\n",
    "    \n",
    "    # Display the results\n",
    "    st.subheader(\"Corrected Text\")\n",
    "    st.write(corrected_text)\n",
    "\n",
    "# Info\n",
    "st.info(\"This app uses TextBlob for spell checking and correction.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095eccf7",
   "metadata": {},
   "source": [
    "# Project 4: Auto Keyword Extraction from Articles Text Using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91c3043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noor Saeed\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\Noor Saeed\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dblp-v10.csv\")\n",
    "df = df[['abstract','authors']]\n",
    "df.dropna(inplace=True)\n",
    "df = df.sample(n=20)\n",
    "df.to_csv(\"small_paper_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2cdf2986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910336</th>\n",
       "      <td>In this paper, we explore the use of Maximum L...</td>\n",
       "      <td>['Diana I. Escalona-Vargas', 'Pamela Murphy', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849061</th>\n",
       "      <td>Even with the recent advances in the area of d...</td>\n",
       "      <td>['Andreas Seekircher', 'Ubbo Visser']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872318</th>\n",
       "      <td>It is challenging to support multimedia transm...</td>\n",
       "      <td>['Chungui Liu', 'Yantai Shu', 'Lianfang Zhang'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85096</th>\n",
       "      <td>Evaluations on the quality of liquid crystal d...</td>\n",
       "      <td>['Eui Chul Lee', 'Si Mong Lee', 'Chee Sun Won'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551574</th>\n",
       "      <td>As three-dimensional (3D) environments become ...</td>\n",
       "      <td>['Hiep Phuc Luong', 'Dipesh Gautam', 'John Gau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132534</th>\n",
       "      <td>Discusses the development of a single, multifu...</td>\n",
       "      <td>['Forouzan Golshani']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25538</th>\n",
       "      <td>We used the finite-element method (FEM) to mod...</td>\n",
       "      <td>['Hong Cao', 'Michael A. Speidel', 'Jang-Zern ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550160</th>\n",
       "      <td>This paper presents a formal specification in ...</td>\n",
       "      <td>['Jonathan Jacky']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106606</th>\n",
       "      <td>The subjective quality achieved by most audio ...</td>\n",
       "      <td>['Claus Bauer', 'Matt Fellers', 'Grant Allen D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740819</th>\n",
       "      <td>This paper presents a supervised bayesian appr...</td>\n",
       "      <td>['Jose San Pedro', 'Alexandros Karatzoglou']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 abstract  \\\n",
       "910336  In this paper, we explore the use of Maximum L...   \n",
       "849061  Even with the recent advances in the area of d...   \n",
       "872318  It is challenging to support multimedia transm...   \n",
       "85096   Evaluations on the quality of liquid crystal d...   \n",
       "551574  As three-dimensional (3D) environments become ...   \n",
       "132534  Discusses the development of a single, multifu...   \n",
       "25538   We used the finite-element method (FEM) to mod...   \n",
       "550160  This paper presents a formal specification in ...   \n",
       "106606  The subjective quality achieved by most audio ...   \n",
       "740819  This paper presents a supervised bayesian appr...   \n",
       "\n",
       "                                                  authors  \n",
       "910336  ['Diana I. Escalona-Vargas', 'Pamela Murphy', ...  \n",
       "849061              ['Andreas Seekircher', 'Ubbo Visser']  \n",
       "872318  ['Chungui Liu', 'Yantai Shu', 'Lianfang Zhang'...  \n",
       "85096   ['Eui Chul Lee', 'Si Mong Lee', 'Chee Sun Won'...  \n",
       "551574  ['Hiep Phuc Luong', 'Dipesh Gautam', 'John Gau...  \n",
       "132534                              ['Forouzan Golshani']  \n",
       "25538   ['Hong Cao', 'Michael A. Speidel', 'Jang-Zern ...  \n",
       "550160                                 ['Jonathan Jacky']  \n",
       "106606  ['Claus Bauer', 'Matt Fellers', 'Grant Allen D...  \n",
       "740819       ['Jose San Pedro', 'Alexandros Karatzoglou']  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ec68e",
   "metadata": {},
   "source": [
    "# clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a40c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "stmer = PorterStemmer()\n",
    "ltzr = WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    # lower casing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove everything except letters and digits, and make lowercase for a continuous string\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # tokenization\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    # remove stopwords\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    \n",
    "    return \" \".join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "275e4e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning enables 890808 computers learn data without explicitly programmed'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample text\n",
    "text = \"Machine! learning enables 890808 @#$#@$#@ computers to? learn from data without being explicitly programmed.\"\n",
    "\n",
    "text = clean(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a0c1286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply on data\n",
    "df['clean_abstract'] = df['abstract'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5aae24d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>clean_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910336</th>\n",
       "      <td>In this paper, we explore the use of Maximum L...</td>\n",
       "      <td>['Diana I. Escalona-Vargas', 'Pamela Murphy', ...</td>\n",
       "      <td>paper explore use maximum likelihood ml method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849061</th>\n",
       "      <td>Even with the recent advances in the area of d...</td>\n",
       "      <td>['Andreas Seekircher', 'Ubbo Visser']</td>\n",
       "      <td>even recent advances area dynamic walking huma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872318</th>\n",
       "      <td>It is challenging to support multimedia transm...</td>\n",
       "      <td>['Chungui Liu', 'Yantai Shu', 'Lianfang Zhang'...</td>\n",
       "      <td>challenging support multimedia transmissions w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85096</th>\n",
       "      <td>Evaluations on the quality of liquid crystal d...</td>\n",
       "      <td>['Eui Chul Lee', 'Si Mong Lee', 'Chee Sun Won'...</td>\n",
       "      <td>evaluations quality liquid crystal display lcd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551574</th>\n",
       "      <td>As three-dimensional (3D) environments become ...</td>\n",
       "      <td>['Hiep Phuc Luong', 'Dipesh Gautam', 'John Gau...</td>\n",
       "      <td>threedimensional 3d environments become preval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132534</th>\n",
       "      <td>Discusses the development of a single, multifu...</td>\n",
       "      <td>['Forouzan Golshani']</td>\n",
       "      <td>discusses development single multifunctional d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25538</th>\n",
       "      <td>We used the finite-element method (FEM) to mod...</td>\n",
       "      <td>['Hong Cao', 'Michael A. Speidel', 'Jang-Zern ...</td>\n",
       "      <td>used finiteelement method fem model analyze re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550160</th>\n",
       "      <td>This paper presents a formal specification in ...</td>\n",
       "      <td>['Jonathan Jacky']</td>\n",
       "      <td>paper presents formal specification z notation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106606</th>\n",
       "      <td>The subjective quality achieved by most audio ...</td>\n",
       "      <td>['Claus Bauer', 'Matt Fellers', 'Grant Allen D...</td>\n",
       "      <td>subjective quality achieved audio codecs inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740819</th>\n",
       "      <td>This paper presents a supervised bayesian appr...</td>\n",
       "      <td>['Jose San Pedro', 'Alexandros Karatzoglou']</td>\n",
       "      <td>paper presents supervised bayesian approach mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 abstract  \\\n",
       "910336  In this paper, we explore the use of Maximum L...   \n",
       "849061  Even with the recent advances in the area of d...   \n",
       "872318  It is challenging to support multimedia transm...   \n",
       "85096   Evaluations on the quality of liquid crystal d...   \n",
       "551574  As three-dimensional (3D) environments become ...   \n",
       "132534  Discusses the development of a single, multifu...   \n",
       "25538   We used the finite-element method (FEM) to mod...   \n",
       "550160  This paper presents a formal specification in ...   \n",
       "106606  The subjective quality achieved by most audio ...   \n",
       "740819  This paper presents a supervised bayesian appr...   \n",
       "\n",
       "                                                  authors  \\\n",
       "910336  ['Diana I. Escalona-Vargas', 'Pamela Murphy', ...   \n",
       "849061              ['Andreas Seekircher', 'Ubbo Visser']   \n",
       "872318  ['Chungui Liu', 'Yantai Shu', 'Lianfang Zhang'...   \n",
       "85096   ['Eui Chul Lee', 'Si Mong Lee', 'Chee Sun Won'...   \n",
       "551574  ['Hiep Phuc Luong', 'Dipesh Gautam', 'John Gau...   \n",
       "132534                              ['Forouzan Golshani']   \n",
       "25538   ['Hong Cao', 'Michael A. Speidel', 'Jang-Zern ...   \n",
       "550160                                 ['Jonathan Jacky']   \n",
       "106606  ['Claus Bauer', 'Matt Fellers', 'Grant Allen D...   \n",
       "740819       ['Jose San Pedro', 'Alexandros Karatzoglou']   \n",
       "\n",
       "                                           clean_abstract  \n",
       "910336  paper explore use maximum likelihood ml method...  \n",
       "849061  even recent advances area dynamic walking huma...  \n",
       "872318  challenging support multimedia transmissions w...  \n",
       "85096   evaluations quality liquid crystal display lcd...  \n",
       "551574  threedimensional 3d environments become preval...  \n",
       "132534  discusses development single multifunctional d...  \n",
       "25538   used finiteelement method fem model analyze re...  \n",
       "550160  paper presents formal specification z notation...  \n",
       "106606  subjective quality achieved audio codecs inclu...  \n",
       "740819  paper presents supervised bayesian approach mo...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4401fcdf",
   "metadata": {},
   "source": [
    "Explanation (bellow code)\n",
    "\n",
    "Nouns: Captures both common and proper nouns (singular and plural).\n",
    "    \n",
    "Adjectives: Includes comparative (JJR) and superlative (JJS) forms in addition to base adjectives (JJ).\n",
    "    \n",
    "Verbs: Includes various forms (base, past, gerund, participle, etc.).\n",
    "    \n",
    "Adverbs: Includes comparative (RBR) and superlative (RBS) adverbs as well as standard adverbs (RB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b5355b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_keywords(text):\n",
    "    # Create a TextBlob object\n",
    "    blob = TextBlob(text)\n",
    "\n",
    "    # Extract a broader range of keywords based on POS tagging\n",
    "    keywords = [word for word, tag in blob.tags if tag in ('NN', 'NNS', 'NNP', 'NNPS',  # Nouns\n",
    "                                                           'JJ', 'JJR', 'JJS',          # Adjectives\n",
    "                                                           'RB', 'RBR', 'RBS')]         # Adverbs\n",
    "\n",
    "    # Count the most common keywords\n",
    "    keyword_counts = Counter(keywords)\n",
    "    most_common_keywords = keyword_counts.most_common(5)  # Get the top 5 most common keywords\n",
    "    \n",
    "    return most_common_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6550744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>clean_abstract</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910336</th>\n",
       "      <td>In this paper, we explore the use of Maximum L...</td>\n",
       "      <td>['Diana I. Escalona-Vargas', 'Pamela Murphy', ...</td>\n",
       "      <td>paper explore use maximum likelihood ml method...</td>\n",
       "      <td>[(ga, 2), (optimization, 2), (fmcg, 2), (data,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849061</th>\n",
       "      <td>Even with the recent advances in the area of d...</td>\n",
       "      <td>['Andreas Seekircher', 'Ubbo Visser']</td>\n",
       "      <td>even recent advances area dynamic walking huma...</td>\n",
       "      <td>[(model, 3), (even, 2), (robots, 2), (signific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872318</th>\n",
       "      <td>It is challenging to support multimedia transm...</td>\n",
       "      <td>['Chungui Liu', 'Yantai Shu', 'Lianfang Zhang'...</td>\n",
       "      <td>challenging support multimedia transmissions w...</td>\n",
       "      <td>[(networks, 5), (wireless, 5), (support, 3), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85096</th>\n",
       "      <td>Evaluations on the quality of liquid crystal d...</td>\n",
       "      <td>['Eui Chul Lee', 'Si Mong Lee', 'Chee Sun Won'...</td>\n",
       "      <td>evaluations quality liquid crystal display lcd...</td>\n",
       "      <td>[(lcd, 4), (tv, 4), (scene, 4), (video, 3), (d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551574</th>\n",
       "      <td>As three-dimensional (3D) environments become ...</td>\n",
       "      <td>['Hiep Phuc Luong', 'Dipesh Gautam', 'John Gau...</td>\n",
       "      <td>threedimensional 3d environments become preval...</td>\n",
       "      <td>[(virtual, 5), (data, 3), (world, 3), (collect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132534</th>\n",
       "      <td>Discusses the development of a single, multifu...</td>\n",
       "      <td>['Forouzan Golshani']</td>\n",
       "      <td>discusses development single multifunctional d...</td>\n",
       "      <td>[(discusses, 1), (development, 1), (single, 1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25538</th>\n",
       "      <td>We used the finite-element method (FEM) to mod...</td>\n",
       "      <td>['Hong Cao', 'Michael A. Speidel', 'Jang-Zern ...</td>\n",
       "      <td>used finiteelement method fem model analyze re...</td>\n",
       "      <td>[(catheter, 5), (fem, 3), (resistance, 3), (de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550160</th>\n",
       "      <td>This paper presents a formal specification in ...</td>\n",
       "      <td>['Jonathan Jacky']</td>\n",
       "      <td>paper presents formal specification z notation...</td>\n",
       "      <td>[(specification, 6), (system, 5), (z, 3), (con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106606</th>\n",
       "      <td>The subjective quality achieved by most audio ...</td>\n",
       "      <td>['Claus Bauer', 'Matt Fellers', 'Grant Allen D...</td>\n",
       "      <td>subjective quality achieved audio codecs inclu...</td>\n",
       "      <td>[(mpeg4, 2), (conventional, 2), (procedure, 2)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740819</th>\n",
       "      <td>This paper presents a supervised bayesian appr...</td>\n",
       "      <td>['Jose San Pedro', 'Alexandros Karatzoglou']</td>\n",
       "      <td>paper presents supervised bayesian approach mo...</td>\n",
       "      <td>[(model, 3), (paper, 1), (presents, 1), (bayes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 abstract  \\\n",
       "910336  In this paper, we explore the use of Maximum L...   \n",
       "849061  Even with the recent advances in the area of d...   \n",
       "872318  It is challenging to support multimedia transm...   \n",
       "85096   Evaluations on the quality of liquid crystal d...   \n",
       "551574  As three-dimensional (3D) environments become ...   \n",
       "132534  Discusses the development of a single, multifu...   \n",
       "25538   We used the finite-element method (FEM) to mod...   \n",
       "550160  This paper presents a formal specification in ...   \n",
       "106606  The subjective quality achieved by most audio ...   \n",
       "740819  This paper presents a supervised bayesian appr...   \n",
       "\n",
       "                                                  authors  \\\n",
       "910336  ['Diana I. Escalona-Vargas', 'Pamela Murphy', ...   \n",
       "849061              ['Andreas Seekircher', 'Ubbo Visser']   \n",
       "872318  ['Chungui Liu', 'Yantai Shu', 'Lianfang Zhang'...   \n",
       "85096   ['Eui Chul Lee', 'Si Mong Lee', 'Chee Sun Won'...   \n",
       "551574  ['Hiep Phuc Luong', 'Dipesh Gautam', 'John Gau...   \n",
       "132534                              ['Forouzan Golshani']   \n",
       "25538   ['Hong Cao', 'Michael A. Speidel', 'Jang-Zern ...   \n",
       "550160                                 ['Jonathan Jacky']   \n",
       "106606  ['Claus Bauer', 'Matt Fellers', 'Grant Allen D...   \n",
       "740819       ['Jose San Pedro', 'Alexandros Karatzoglou']   \n",
       "\n",
       "                                           clean_abstract  \\\n",
       "910336  paper explore use maximum likelihood ml method...   \n",
       "849061  even recent advances area dynamic walking huma...   \n",
       "872318  challenging support multimedia transmissions w...   \n",
       "85096   evaluations quality liquid crystal display lcd...   \n",
       "551574  threedimensional 3d environments become preval...   \n",
       "132534  discusses development single multifunctional d...   \n",
       "25538   used finiteelement method fem model analyze re...   \n",
       "550160  paper presents formal specification z notation...   \n",
       "106606  subjective quality achieved audio codecs inclu...   \n",
       "740819  paper presents supervised bayesian approach mo...   \n",
       "\n",
       "                                                 keywords  \n",
       "910336  [(ga, 2), (optimization, 2), (fmcg, 2), (data,...  \n",
       "849061  [(model, 3), (even, 2), (robots, 2), (signific...  \n",
       "872318  [(networks, 5), (wireless, 5), (support, 3), (...  \n",
       "85096   [(lcd, 4), (tv, 4), (scene, 4), (video, 3), (d...  \n",
       "551574  [(virtual, 5), (data, 3), (world, 3), (collect...  \n",
       "132534  [(discusses, 1), (development, 1), (single, 1)...  \n",
       "25538   [(catheter, 5), (fem, 3), (resistance, 3), (de...  \n",
       "550160  [(specification, 6), (system, 5), (z, 3), (con...  \n",
       "106606  [(mpeg4, 2), (conventional, 2), (procedure, 2)...  \n",
       "740819  [(model, 3), (paper, 1), (presents, 1), (bayes...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get keywords\n",
    "df['keywords'] = df['clean_abstract'].apply(get_keywords)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a369678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910336    [(ga, 2), (optimization, 2), (fmcg, 2), (data,...\n",
       "849061    [(model, 3), (even, 2), (robots, 2), (signific...\n",
       "872318    [(networks, 5), (wireless, 5), (support, 3), (...\n",
       "85096     [(lcd, 4), (tv, 4), (scene, 4), (video, 3), (d...\n",
       "551574    [(virtual, 5), (data, 3), (world, 3), (collect...\n",
       "132534    [(discusses, 1), (development, 1), (single, 1)...\n",
       "25538     [(catheter, 5), (fem, 3), (resistance, 3), (de...\n",
       "550160    [(specification, 6), (system, 5), (z, 3), (con...\n",
       "106606    [(mpeg4, 2), (conventional, 2), (procedure, 2)...\n",
       "740819    [(model, 3), (paper, 1), (presents, 1), (bayes...\n",
       "Name: keywords, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keywords']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57cedb4",
   "metadata": {},
   "source": [
    "# App.py (Don't run it here, run in vs or pycharm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "import\n",
    "# run this in terminal; python -m nltk.downloader all\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    # lower casing\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove everything except letters and digits, and make lowercase for a continuous string\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # tokenization\n",
    "    text = word_tokenize(text)\n",
    "\n",
    "    # remove stopwords\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "\n",
    "def get_keywords(text):\n",
    "    # Create a TextBlob object\n",
    "    blob = TextBlob(text)\n",
    "\n",
    "    # Extract a broader range of keywords based on POS tagging\n",
    "    keywords = [word for word, tag in blob.tags if tag in ('NN', 'NNS', 'NNP', 'NNPS',  # Nouns\n",
    "                                                           'JJ', 'JJR', 'JJS',  # Adjectives\n",
    "                                                           'RB', 'RBR', 'RBS')]  # Adverbs\n",
    "\n",
    "    # Count the most common keywords\n",
    "    keyword_counts = Counter(keywords)\n",
    "    most_common_keywords = keyword_counts.most_common(5)  # Get the top 5 most common keywords\n",
    "\n",
    "    return most_common_keywords\n",
    "\n",
    "\n",
    "# UI code=================\n",
    "st.title(\"Auto Keyword Extraction from Articles Text Using TextBlob\")\n",
    "uploaded_file = st.sidebar.file_uploader(\"Upload a file\", type=\"csv\")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # read dataset\n",
    "    df = pd.read_csv(uploaded_file)\n",
    "    df = df[['abstract', 'authors']]\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.sample(n=20)\n",
    "    # apply on data\n",
    "    st.write(\"Uploaded File Preview\")\n",
    "    st.dataframe(df.head(3))\n",
    "\n",
    "    # Check if the 'abstract' column exists and is not empty\n",
    "    if 'abstract' in df.columns and not df['abstract'].empty:\n",
    "        df['clean_abstract'] = df['abstract'].apply(clean)\n",
    "        df['keywords'] = df['clean_abstract'].apply(get_keywords)\n",
    "\n",
    "\n",
    "\n",
    "        # Ensure keywords column contains only strings\n",
    "        df['keywords'] = df['keywords'].apply(lambda x: str(x) if not isinstance(x, str) else x)\n",
    "        # Handle NaN or None values by replacing them with an empty string\n",
    "        df['keywords'] = df['keywords'].fillna('')\n",
    "        st.write(\"Extracted Keywords Preview\")\n",
    "        st.dataframe(df)\n",
    "    else:\n",
    "        st.write(\"Uploaded Data must have abstract column...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
